{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1vcMNR4DXoRM1EVJAaq4SgnWQSZ2bgYLQ","authorship_tag":"ABX9TyNLC+yzqDApzxH/pVP6jxmW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"id":"xKgHHguhSYvm","executionInfo":{"status":"ok","timestamp":1667459585245,"user_tz":240,"elapsed":1230,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"outputs":[],"source":["import numpy as np\n","import re\n","import nltk\n","from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense, Bidirectional\n","from keras.models import Model, load_model\n","import tensorflow as tf\n","from keras.layers import SimpleRNN\n","from keras.layers import Embedding\n","from keras.layers import Input, Dense, LSTM, TimeDistributed\n","from keras.models import Model"]},{"cell_type":"code","source":["#Global Variables declaration and intitialization\n","INPUT_VECTOR_LENGTH = 20\n","OUTPUT_VECTORLENGTH = 20\n","minimum_length = 2\n","maximum_length = 20\n","sample_size = 30000 \n","WORD_START = 1\n","WORD_PADDING = 0\n","GLOVE_MODEL = \"/content/drive/MyDrive/colab/glove.6B.50d.txt\""],"metadata":{"id":"9-BzRE0WGo0i","executionInfo":{"status":"ok","timestamp":1667459587384,"user_tz":240,"elapsed":5,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["\n","\n","exit_words = [\n","        'bye', 'goodbye', 'exit', \n","        'tata','see you','terminate',\n","        'Bye', 'Goodbye', 'Exit',\n","        'Tata','See you','Terminate'\n","         ]\n","\n"],"metadata":{"id":"hB72JkUhGo3M","executionInfo":{"status":"ok","timestamp":1667459589399,"user_tz":240,"elapsed":6,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\n","\n","#Mapping the Ids to lines and splitting the lines by using the delimiter.\n","def map_linetoID(movie_lines):\n","    linetoID_mapping = {}\n","    for line in movie_lines:\n","        split_line = line.split(' +++$+++ ')\n","        if len(split_line) == 5:\n","            linetoID_mapping[split_line[0]] = split_line[4]\n","    return linetoID_mapping\n","\n"],"metadata":{"id":"6YlBn73CGo5X","executionInfo":{"status":"ok","timestamp":1667459592196,"user_tz":240,"elapsed":857,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#Splitting the converstions by the delimiter and creating a list of coversation ID's.\n","def extract_converstionIDs(conversation_lines):\n","    conversations = []\n","    for line in conversation_lines[:-1]:\n","        split_line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n","        conversations.append(split_line.split(','))\n","    return conversations"],"metadata":{"id":"d96EvuIiGo-K","executionInfo":{"status":"ok","timestamp":1667459595216,"user_tz":240,"elapsed":6,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["\n","\n","#Function is used to form pairs of questions and answers.\n","def extract_quesans_pairs(linetoID_mapping,conversations):\n","    questions = []\n","    answers = []\n","    for con in conversations:\n","        for i in range(len(con)-1):\n","            questions.append(linetoID_mapping[con[i]])\n","            answers.append(linetoID_mapping[con[i+1]])\n","    return questions,answers\n","\n"],"metadata":{"id":"6I62coHYGpAf","executionInfo":{"status":"ok","timestamp":1667459595859,"user_tz":240,"elapsed":3,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["#Function is used to transsfrom the text\n","#For example I'm gets transformed to I am\n","def transform_text(input_text):\n","    input_text = input_text.lower()\n","    input_text = re.sub(r\"I'm\", \"I am\", input_text)\n","    input_text = re.sub(r\"he's\", \"he is\", input_text)\n","    input_text = re.sub(r\"she's\", \"she is\", input_text)\n","    input_text = re.sub(r\"it's\", \"it is\", input_text)\n","    input_text = re.sub(r\"that's\", \"that is\", input_text)\n","    input_text = re.sub(r\"what's\", \"that is\", input_text)\n","    input_text = re.sub(r\"where's\", \"where is\", input_text)\n","    input_text = re.sub(r\"how's\", \"how is\", input_text)\n","    input_text = re.sub(r\"\\'ll\", \" will\", input_text)\n","    input_text = re.sub(r\"\\'ve\", \" have\", input_text)\n","    input_text = re.sub(r\"\\'re\", \" are\", input_text)\n","    input_text = re.sub(r\"\\'d\", \" would\", input_text)\n","    input_text = re.sub(r\"\\'re\", \" are\", input_text)\n","    input_text = re.sub(r\"won't\", \"will not\", input_text)\n","    input_text = re.sub(r\"can't\", \"cannot\", input_text)\n","    input_text = re.sub(r\"n't\", \" not\", input_text)\n","    input_text = re.sub(r\"'til\", \"until\", input_text)\n","    input_text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|]\", \"\", input_text)\n","    input_text = \" \".join(input_text.split())\n","    return input_text"],"metadata":{"id":"FgW-VJFyGpCv","executionInfo":{"status":"ok","timestamp":1667459597890,"user_tz":240,"elapsed":6,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["\n","\n","#Filter the questions and answer. The minimum length is 2 and \n","#maximum is 20\n","def filter_ques_ans(clean_questions,clean_answers):\n","    # Filter out the questions that are too short/long\n","    short_questions_temp = []\n","    short_answers_temp = []\n","    for i, question in enumerate(clean_questions):\n","        if len(question.split()) >= minimum_length and len(question.split()) <= maximum_length:\n","            short_questions_temp.append(question)\n","            short_answers_temp.append(clean_answers[i])\n","    short_questions = []\n","    short_answers = []\n","    for i, answer in enumerate(short_answers_temp):\n","        if len(answer.split()) >= minimum_length and len(answer.split()) <= maximum_length:\n","            short_answers.append(answer)\n","            short_questions.append(short_questions_temp[i])\n","    return short_questions,short_answers\n","\n"],"metadata":{"id":"MPwwMXx8GpFO","executionInfo":{"status":"ok","timestamp":1667459540517,"user_tz":240,"elapsed":700,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#Calculate the word count \n","def create_vocabulary(tokenized_ques,tokenized_ans):\n","    vocabulary = {}\n","    for question in tokenized_ques:\n","        for word in question:\n","            if word not in vocabulary:\n","                vocabulary[word] = 1\n","            else:\n","                vocabulary[word] += 1\n","    for answer in tokenized_ans:\n","        for word in answer:\n","            if word not in vocabulary:\n","                vocabulary[word] = 1\n","            else:\n","                vocabulary[word] += 1  \n","    return vocabulary"],"metadata":{"id":"mQ78e0UNGpHM","executionInfo":{"status":"ok","timestamp":1667459603717,"user_tz":240,"elapsed":721,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["\n","\n","#Create the encodings and decodings by assigning unique \n","#index to the words.\n","def create_encoding_decoding(vocabulary):\n","    threshold = 15\n","    count = 0\n","    for k,v in vocabulary.items():\n","        if v >= threshold:\n","            count += 1\n","    vocab_size  = 2 \n","    encoding = {}\n","    decoding = {1: 'START'}\n","    for word, count in vocabulary.items():\n","        if count >= threshold:\n","            encoding[word] = vocab_size \n","            decoding[vocab_size ] = word\n","            vocab_size += 1\n","    return encoding,decoding,vocab_size\n","\n"],"metadata":{"id":"WiA2g1RYGpJG","executionInfo":{"status":"ok","timestamp":1667459605854,"user_tz":240,"elapsed":4,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["#Convert the training and validation data into vectors\n","def transform(encoding, data, vector_size=20):\n","    transformed_data = np.zeros(shape=(len(data), vector_size))\n","    for i in range(len(data)):\n","        for j in range(min(len(data[i]), vector_size)):\n","            try:\n","                transformed_data[i][j] = encoding[data[i][j]]\n","            except:\n","                transformed_data[i][j] = encoding['']\n","    return transformed_data"],"metadata":{"id":"IDdBuBmJI0vN","executionInfo":{"status":"ok","timestamp":1667459610509,"user_tz":240,"elapsed":438,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["\n","\n","#Create glove embeddings form the pre-trained glove model.\n","def create_gloveEmbeddings(encoding,size):\n","    file = open(GLOVE_MODEL, mode='rt', encoding='utf8')\n","    words = set()\n","    word_to_vec_map = {}\n","    for line in file:\n","        line = line.strip().split()\n","        word = line[0]\n","        words.add(word)\n","        word_to_vec_map[word] = np.array(line[1:], dtype=np.float64)\n","    embedding_matrix = np.zeros((size, 50))\n","    for word,index in encoding.items():\n","        try:\n","            embedding_matrix[index, :] = word_to_vec_map[word.lower()]\n","        except: continue\n","    return embedding_matrix\n","\n"],"metadata":{"id":"9MxR_sXaI0xo","executionInfo":{"status":"ok","timestamp":1667459613047,"user_tz":240,"elapsed":6,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["#Creating the LSTM model\n","def create_model(dict_size,embed_layer,hidden_dim):\n","    \n","    encoder_inputs = Input(shape=(maximum_length, ), dtype='int32',)\n","    encoder_embedding = embed_layer(encoder_inputs)\n","    encoder_LSTM = LSTM(hidden_dim, return_state=True)\n","    encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n","    decoder_inputs = Input(shape=(maximum_length, ), dtype='int32',)\n","    decoder_embedding = embed_layer(decoder_inputs)\n","    decoder_LSTM = LSTM(hidden_dim, return_state=True, return_sequences=True)\n","    decoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=[state_h, state_c])\n","    outputs = TimeDistributed(Dense(dict_size, activation='softmax'))(decoder_outputs)\n","    model = Model([encoder_inputs, decoder_inputs], outputs)\n","    return model"],"metadata":{"id":"v2nV75vRI0z1","executionInfo":{"status":"ok","timestamp":1667459616512,"user_tz":240,"elapsed":716,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["\n","\n","# predicting the answer to the question\n","#and returning the output vectors.\n","def prediction_answer(user_input,model):\n","    transformed_input = transform_text(user_input)\n","    input_tokens = [nltk.word_tokenize(transformed_input)]\n","    input_tokens = [input_tokens[0][::-1]]  #reverseing input seq\n","    encoder_input = transform(encoding, input_tokens, 20)\n","    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_VECTORLENGTH))\n","    decoder_input[:,0] = WORD_START\n","    for i in range(1, OUTPUT_VECTORLENGTH):\n","        pred_output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n","        decoder_input[:,i] = pred_output[:,i]\n","    return pred_output\n","\n"],"metadata":{"id":"OSM4ubMPI02K","executionInfo":{"status":"ok","timestamp":1667459506646,"user_tz":240,"elapsed":481,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#decoding the vectors.\n","def decode_answer(decoding, ans_vec):\n","    ans = ''\n","    for i in ans_vec:\n","        if i == 0:\n","            break\n","        ans += ' '\n","        ans += decoding[i]\n","    return ans"],"metadata":{"id":"3WaR7R0hI04H","executionInfo":{"status":"ok","timestamp":1667459510506,"user_tz":240,"elapsed":448,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Also could use \n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","linetoID_mapping={}\n","conversations=[]\n","#Reading the conversational data\n","movie_lines = open('/content/drive/MyDrive/colab/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n","conversation_lines = open('/content/drive/MyDrive/colab/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n","#calling map_linetoID()\n","linetoID_mapping=map_linetoID(movie_lines)\n","    \n","#calling extract_converstions()\n","conversations=extract_converstionIDs(conversation_lines)\n","    \n","#extracting question answer pairs\n","questions,answers=extract_quesans_pairs(linetoID_mapping,conversations)\n","transformed_ques = []\n","for question in questions:\n","    transformed_ques.append( transform_text(question))\n","transformed_answers = []    \n","for answer in answers:\n","     transformed_answers.append(transform_text(answer))\n","    \n","#Limiting the length of questionas and answers\n","filtered_questions=[]\n","filtered_answers=[]\n","filtered_questions,filtered_answers=filter_ques_ans(transformed_ques,transformed_answers)\n","    \n","#Tokeninzing\n","filtered_questions = filtered_questions[:sample_size]\n","filtered_answers = filtered_answers[:sample_size]\n","#tokenizing the questions and answers\n","tokenized_ques = [nltk.word_tokenize(sent) for sent in filtered_questions]\n","tokenized_ans = [nltk.word_tokenize(sent) for sent in filtered_answers]\n","    \n","#Splitting the data into training and validation datasets\n","size = len(tokenized_ques)\n","training_input  = tokenized_ques[:round(size*(80/100))]\n","training_input  = [tr_input[::-1] for tr_input in training_input] #reverseing input seq for better performance\n","training_output = tokenized_ans[:round(size*(80/100))]\n","\n","# We will use the remaining for validation\n","validation_input = tokenized_ques[round(size*(80/100)):]\n","validation_input  = [val_input[::-1] for val_input in validation_input] #reverseing input seq for better performance\n","validation_output = tokenized_ans[round(size*(80/100)):]\n","\n","print('Number of Samples used for training:', len(training_input))\n","print('Number of samples in the validation:', len(validation_input))\n","    \n","#creating vacabulary\n","vocabulary={}\n","vocabulary=create_vocabulary(tokenized_ques,tokenized_ans)\n","print(\"Length of vocabulary:\", len(vocabulary))\n","    \n","#creating encodings and decodings\n","dict_size=0\n","encoding={}\n","decoding={}\n","encoding,decoding,dict_size=create_encoding_decoding(vocabulary)\n","dict_size=dict_size+1\n","decoding[len(encoding)+2] = ''\n","encoding[''] = len(encoding)+2\n","print(\"The size of the dictionary:\",dict_size)\n","print(\"The size of encoding:\",len(encoding))\n","print(\"The size of decoding:\",len(decoding))\n","    \n","    \n","#Function call to the transform function\n","encoded_training_input = transform(\n","encoding, training_input, vector_size=INPUT_VECTOR_LENGTH)\n","encoded_training_output = transform(\n","encoding, training_output, vector_size=OUTPUT_VECTORLENGTH)\n","print('Shape of Encoded Training Input', encoded_training_input.shape)\n","print('Shape of Encoded Training Output', encoded_training_output.shape)\n","    \n","#For Validation data \n","encoded_validation_input = transform(\n","encoding, validation_input, vector_size=INPUT_VECTOR_LENGTH)\n","encoded_validation_output = transform(\n","encoding, validation_output, vector_size=OUTPUT_VECTORLENGTH)\n","print('Shape of Encoded validation Input', encoded_validation_input.shape)\n","print('Shape of Encoded validation Output', encoded_validation_output.shape)\n","    \n","#Create the glove embedding which will be used as weights for the embedding layer.\n","tf.keras.backend.clear_session()\n","embedding_matrix = np.zeros((dict_size, 50))\n","embedding_matrix= create_gloveEmbeddings(encoding,dict_size)\n","print(embedding_matrix.shape)\n","    \n","#forming th embedding layer\n","embed_layer = Embedding(input_dim=dict_size, output_dim=50, trainable=True,)\n","embed_layer.build((None,))\n","embed_layer.set_weights([embedding_matrix])\n","    \n","#creating model\n","hidden_dim=300\n","lstm_model = create_model(dict_size,embed_layer,hidden_dim)\n","#getting the summary of model\n","lstm_model.summary()\n","    \n","# #compiling the model\n","# lstm_model.compile(optimizer='adam', loss ='categorical_crossentropy', metrics = ['accuracy'])\n","    \n","# training_encoder_input = encoded_training_input\n","# training_decoder_input = np.zeros_like(encoded_training_output)\n","# training_decoder_input[:, 1:] = encoded_training_output[:,:-1]\n","# training_decoder_input[:, 0] = WORD_START\n","# training_decoder_output = np.eye(dict_size)[encoded_training_output.astype('int32')]\n","\n","# validation_encoder_input = encoded_validation_input\n","# validation_decoder_input = np.zeros_like(encoded_validation_output)\n","# validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n","# validation_decoder_input[:, 0] = WORD_START\n","# validation_decoder_output = np.eye(dict_size)[encoded_validation_output.astype('int32')]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZRWcmw_fI06-","executionInfo":{"status":"ok","timestamp":1667459714889,"user_tz":240,"elapsed":19578,"user":{"displayName":"sophie white","userId":"12191687335629451267"}},"outputId":"4f501174-dfd3-4a45-ee2c-e1d511957c00"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Number of Samples used for training: 24000\n","Number of samples in the validation: 6000\n","Length of vocabulary: 16412\n","The size of the dictionary: 1967\n","The size of encoding: 1965\n","The size of decoding: 1966\n","Shape of Encoded Training Input (24000, 20)\n","Shape of Encoded Training Output (24000, 20)\n","Shape of Encoded validation Input (6000, 20)\n","Shape of Encoded validation Output (6000, 20)\n","(1967, 50)\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, 20)]         0           []                               \n","                                                                                                  \n"," input_1 (InputLayer)           [(None, 20)]         0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 20, 50)       98350       ['input_1[0][0]',                \n","                                                                  'input_2[0][0]']                \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 300),        421200      ['embedding[0][0]']              \n","                                 (None, 300),                                                     \n","                                 (None, 300)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, 20, 300),    421200      ['embedding[1][0]',              \n","                                 (None, 300),                     'lstm[0][1]',                   \n","                                 (None, 300)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," time_distributed (TimeDistribu  (None, 20, 1967)    592067      ['lstm_1[0][0]']                 \n"," ted)                                                                                             \n","                                                                                                  \n","==================================================================================================\n","Total params: 1,532,817\n","Trainable params: 1,532,817\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["#fitting the model\n","lstm_model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n","    validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n","          batch_size=64, epochs=10)"],"metadata":{"id":"JL3I9hzwGpLA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_model.save('lstm_model_glove_embeddings.h5')"],"metadata":{"id":"ctTmDrPoNPmT","executionInfo":{"status":"ok","timestamp":1667458840271,"user_tz":240,"elapsed":45,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["\n","\n","from keras.models import load_model\n","lstm_model=load_model('/content/drive/MyDrive/colab/lstm_model_glove_embeddings.h5')\n","\n"],"metadata":{"id":"dIBjMQVWNPo0","executionInfo":{"status":"ok","timestamp":1667459477677,"user_tz":240,"elapsed":12061,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["\n","\n","#Printing the sample Questions and answers.\n","for i in range(20):\n","    output = prediction_answer(filtered_questions[i],lstm_model)\n","    print ('Question:', filtered_questions[i])\n","    print ('Answer:', decode_answer(decoding, output[0]))\n","    i=i+1\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xbAEJmNkNPrX","executionInfo":{"status":"ok","timestamp":1667459755083,"user_tz":240,"elapsed":26429,"user":{"displayName":"sophie white","userId":"12191687335629451267"}},"outputId":"a3714271-7e24-47fb-ff04-571ac776d75f"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 5s 5s/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Question: well, i thought we would start with pronunciation, if that is okay with you.\n","Answer: \n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","Question: not the hacking and gagging and spitting part. please.\n","Answer: \n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 16ms/step\n","Question: you are asking me out. that is so cute. that is your name again?\n","Answer: \n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Question: gosh, if only we could find kat a boyfriend...\n","Answer: \n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 17ms/step\n","Question: c'esc ma tete. this is my head\n","Answer: \n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Question: that is because it is such a nice one.\n","Answer: \n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","Question: how is our little find the wench a date plan progressing?\n","Answer: \n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Question: you have my word. as a gentleman\n","Answer: \n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 16ms/step\n","Question: how do you get your hair to look like that?\n","Answer: \n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Question: sure have.\n","Answer: \n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","Question: i really, really, really wanna go, but i cannot. not unless my sister goes.\n","Answer: \n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","Question: so that is the kind of guy she likes? pretty ones?\n","Answer: \n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","Question: you know chastity?\n","Answer: \n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Question: i looked for you back at the party, but you always seemed to be occupied.\n","Answer: \n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","Question: i was?\n","Answer: \n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","Question: well, no...\n","Answer: \n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","Question: do you listen to this crap?\n","Answer: \n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 18ms/step\n","Question: what crap?\n","Answer: \n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","Question: me. this endless ...blonde babble. i'm like, boring myself.\n","Answer: \n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 16ms/step\n","Question: i figured you would get to the good stuff eventually.\n","Answer: \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lJLwFNiwNPtu","executionInfo":{"status":"ok","timestamp":1667458840273,"user_tz":240,"elapsed":40,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Votac_eLNPvv","executionInfo":{"status":"ok","timestamp":1667458840274,"user_tz":240,"elapsed":40,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XFxLVznLGpNI","executionInfo":{"status":"ok","timestamp":1667458840275,"user_tz":240,"elapsed":40,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"execution_count":17,"outputs":[]}]}