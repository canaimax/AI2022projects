{"cells":[{"cell_type":"markdown","metadata":{"id":"bpqGrvbUrQRE"},"source":["## Hard Hat Detector\n","\n","### Initialize the Libraries"]},{"cell_type":"code","source":["!pip install tensorflow==2.4.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-XdqVzNztUjX","executionInfo":{"status":"ok","timestamp":1660201432986,"user_tz":240,"elapsed":88411,"user":{"displayName":"sophie white","userId":"12191687335629451267"}},"outputId":"3e0a681b-c578-4f97-8b04-53eb8c3ef91c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.4.0\n","  Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n","\u001b[K     |████████████████████████████████| 394.7 MB 17 kB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.17.3)\n","Collecting absl-py~=0.10\n","  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 63.3 MB/s \n","\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.37.1)\n","Collecting h5py~=2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 47.8 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.8.0)\n","Collecting numpy~=1.19.2\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","\u001b[K     |████████████████████████████████| 14.8 MB 45.6 MB/s \n","\u001b[?25hCollecting wrapt~=1.12.1\n","  Downloading wrapt-1.12.1.tar.gz (27 kB)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.2.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.6.3)\n","Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n","  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 60.6 MB/s \n","\u001b[?25hCollecting typing-extensions~=3.7.4\n","  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.2)\n","Collecting grpcio~=1.32.0\n","  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 41.1 MB/s \n","\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.15.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.0)\n","Collecting flatbuffers~=1.12.0\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.3.0)\n","Collecting gast==0.3.3\n","  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.6.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (57.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.35.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.2.0)\n","Building wheels for collected packages: wrapt\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68721 sha256=017727de24a2e9810ee58b1e1b2be00b5f4ccbb67b93db36aca7321ded95fee4\n","  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n","Successfully built wrapt\n","Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, h5py, gast, flatbuffers, tensorflow\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.1.1\n","    Uninstalling typing-extensions-4.1.1:\n","      Successfully uninstalled typing-extensions-4.1.1\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.47.0\n","    Uninstalling grpcio-1.47.0:\n","      Successfully uninstalled grpcio-1.47.0\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.2.0\n","    Uninstalling absl-py-1.2.0:\n","      Successfully uninstalled absl-py-1.2.0\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.14.1\n","    Uninstalling wrapt-1.14.1:\n","      Successfully uninstalled wrapt-1.14.1\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 2.0\n","    Uninstalling flatbuffers-2.0:\n","      Successfully uninstalled flatbuffers-2.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n","    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n","      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n","cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n","Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 numpy-1.19.5 tensorflow-2.4.0 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","typing_extensions"]}}},"metadata":{}}]},{"cell_type":"code","source":["!pip install opencv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QA95BrFptWWU","executionInfo":{"status":"ok","timestamp":1660201443888,"user_tz":240,"elapsed":2399,"user":{"displayName":"sophie white","userId":"12191687335629451267"}},"outputId":"fa07a991-acb0-4666-d4bd-5c61ac057e15"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement opencv (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for opencv\u001b[0m\n"]}]},{"cell_type":"code","source":["pip install keras==2.4.3 numpy==1.19.3 pillow==7.0.0 scipy==1.4.1 h5py==2.10.0 matplotlib==3.3.2 opencv-python keras-resnet==0.2.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"VMggZnRztWYj","executionInfo":{"status":"ok","timestamp":1660201475216,"user_tz":240,"elapsed":27415,"user":{"displayName":"sophie white","userId":"12191687335629451267"}},"outputId":"eacd39ae-b77f-48d5-cb35-e757fe8bc3de"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras==2.4.3\n","  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n","Collecting numpy==1.19.3\n","  Downloading numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl (14.9 MB)\n","\u001b[K     |████████████████████████████████| 14.9 MB 6.7 MB/s \n","\u001b[?25hCollecting pillow==7.0.0\n","  Downloading Pillow-7.0.0-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 49.1 MB/s \n","\u001b[?25hCollecting scipy==1.4.1\n","  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n","\u001b[K     |████████████████████████████████| 26.1 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n","Collecting matplotlib==3.3.2\n","  Downloading matplotlib-3.3.2-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n","\u001b[K     |████████████████████████████████| 11.6 MB 61.8 MB/s \n","\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n","Collecting keras-resnet==0.2.0\n","  Downloading keras-resnet-0.2.0.tar.gz (9.3 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (3.13)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2) (2.8.2)\n","Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2) (2022.6.15)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.3.2) (3.7.4.3)\n","Building wheels for collected packages: keras-resnet\n","  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20486 sha256=ced69d3c1441189f8991bb93977127eb2fdb3841462eef035819513832dd967e\n","  Stored in directory: /root/.cache/pip/wheels/bd/ef/06/5d65f696360436c3a423020c4b7fd8c558c09ef264a0e6c575\n","Successfully built keras-resnet\n","Installing collected packages: numpy, scipy, pillow, keras, matplotlib, keras-resnet\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.7.3\n","    Uninstalling scipy-1.7.3:\n","      Successfully uninstalled scipy-1.7.3\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.8.0\n","    Uninstalling keras-2.8.0:\n","      Successfully uninstalled keras-2.8.0\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.3 which is incompatible.\n","pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.4.1 which is incompatible.\n","jaxlib 0.3.14+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n","jax 0.3.14 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n","cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.19.3 which is incompatible.\n","bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 7.0.0 which is incompatible.\u001b[0m\n","Successfully installed keras-2.4.3 keras-resnet-0.2.0 matplotlib-3.3.2 numpy-1.19.3 pillow-7.0.0 scipy-1.4.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","matplotlib","mpl_toolkits","numpy"]}}},"metadata":{}}]},{"cell_type":"code","source":["pip install imageai --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O3iy0JAdtWat","executionInfo":{"status":"ok","timestamp":1660201528295,"user_tz":240,"elapsed":5125,"user":{"displayName":"sophie white","userId":"12191687335629451267"}},"outputId":"2e2ab520-af0e-4a57-f10b-e931ca660fed"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting imageai\n","  Downloading imageai-2.1.6-py3-none-any.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from imageai) (2.10.0)\n","Requirement already satisfied: matplotlib==3.3.2 in /usr/local/lib/python3.7/dist-packages (from imageai) (3.3.2)\n","Requirement already satisfied: keras==2.4.3 in /usr/local/lib/python3.7/dist-packages (from imageai) (2.4.3)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imageai) (4.6.0.66)\n","Requirement already satisfied: keras-resnet==0.2.0 in /usr/local/lib/python3.7/dist-packages (from imageai) (0.2.0)\n","Requirement already satisfied: numpy==1.19.3 in /usr/local/lib/python3.7/dist-packages (from imageai) (1.19.3)\n","Requirement already satisfied: pillow==7.0.0 in /usr/local/lib/python3.7/dist-packages (from imageai) (7.0.0)\n","Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from imageai) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->imageai) (1.15.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3->imageai) (3.13)\n","Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2022.6.15)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (1.4.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.3.2->imageai) (3.7.4.3)\n","Installing collected packages: imageai\n","Successfully installed imageai-2.1.6\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"HKPIyHVDtWc-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Z-RX7_ottWe8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"-KQ1LcMvrQRJ","executionInfo":{"status":"ok","timestamp":1660201536307,"user_tz":240,"elapsed":3530,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"outputs":[],"source":["import cv2 as cv\n","from imageai.Detection import ObjectDetection\n","\n","import numpy as np\n","import requests as req\n","import os as os"]},{"cell_type":"markdown","metadata":{"id":"iTWhCsecrQRM"},"source":["### Show Window Function"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"cjw2yjzzrQRN","executionInfo":{"status":"ok","timestamp":1660201543751,"user_tz":240,"elapsed":10,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"outputs":[],"source":["def showImage(img):\n","    window_name = 'image'\n","    cv.imshow(window_name, img)\n","    cv.waitKey(0)\n","    cv.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"iEUlsCfOrQRP"},"source":["## Download Data\n","\n","### Download Images of Hard Hats"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"5jSgeGhbrQRP","executionInfo":{"status":"ok","timestamp":1660201626751,"user_tz":240,"elapsed":1332,"user":{"displayName":"sophie white","userId":"12191687335629451267"}}},"outputs":[],"source":["hardhatLoc = 'http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n03492922'\n","\n","hardhatImages = req.get(hardhatLoc).text\n","noOfImages = 0\n","\n","if not os.path.exists('hardhat'):\n","    os.makedirs('hardhat')\n"]},{"cell_type":"code","source":["\n","for i in hardhatImages.split('\\n'):\n","    \n","        r = req.get(i, timeout=0.5)\n","        file = i.split(\"/\")[-1].split('\\r')[0]\n","        if 'image/jpeg' in r.headers['Content-Type']:\n","            if len(r.content) > 8192:\n","                with open('hardhat\\\\' + file, 'wb') as outfile:\n","                    outfile.write(r.content)\n","                    noOfImages += 1\n","                    print('Success: ' + file)\n","\n","        \n","print('*********** Download Finished **************')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"9fphK5Dtull5","executionInfo":{"status":"error","timestamp":1660201716465,"user_tz":240,"elapsed":421,"user":{"displayName":"sophie white","userId":"12191687335629451267"}},"outputId":"32146635-f9d5-4dbd-c3f8-ad38fd7eef0a"},"execution_count":12,"outputs":[{"output_type":"error","ename":"MissingSchema","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-b3c30f6a93a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhardhatImages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'image/jpeg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Content-Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         )\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         )\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_native_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMissingSchema\u001b[0m: Invalid URL '<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">': No schema supplied. Perhaps you meant http://<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">?"]}]},{"cell_type":"markdown","metadata":{"id":"TS4iJ4LOrQRQ"},"source":["### Download Images of People"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_WFqhqT7rQRR"},"outputs":[],"source":["peopleLoc = 'http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n07942152'\n","\n","peopleImages = req.get(peopleLoc).text\n","noOfImages = 0\n","\n","if not os.path.exists('people'):\n","    os.makedirs('people')\n","\n","for i in peopleImages.split('\\n'):\n","    try:\n","        r = req.get(i, timeout=0.5)\n","        file = i.split(\"/\")[-1].split('\\r')[0]\n","        if 'image/jpeg' in r.headers['Content-Type']:\n","            if len(r.content) > 8192:\n","                with open('people\\\\' + file, 'wb') as outfile:\n","                    outfile.write(r.content)\n","                    noOfImages += 1\n","                    print('Success: ' + file)\n","            else:\n","                print('Failed: ' + file + ' -- Image too small')\n","        else:\n","            print('Failed: ' + file + ' -- Not an image')\n","\n","    except Exception as e:\n","        print('Failed: ' + file + ' -- Error')\n","        \n","print('*********** Download Finished **************')"]},{"cell_type":"markdown","metadata":{"id":"jOjEUvWtrQRR"},"source":["### Download Pre-Train Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8hCR707brQRS"},"outputs":[],"source":["modelRetinaNet = 'https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/resnet50_coco_best_v2.0.1.h5'\n","modelYOLOv3 = 'https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo.h5'\n","modelTinyYOLOv3 = 'https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo-tiny.h5'\n","\n","if not os.path.exists('yolo.h5'):\n","    r = req.get(modelYOLOv3, timeout=0.5)\n","    with open('yolo.h5', 'wb') as outfile:\n","        outfile.write(r.content)"]},{"cell_type":"markdown","metadata":{"id":"mQn1fh8xrQRT"},"source":["## Train the Model\n","\n","### Define the Detector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rBg7Vo3ZrQRT","outputId":"83d10929-5197-4872-905f-6d5db0a90a66"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From E:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From E:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"]}],"source":["detector = ObjectDetection()\n","detector.setModelTypeAsYOLOv3()\n","detector.setModelPath('yolo.h5')\n","detector.loadModel()"]},{"cell_type":"markdown","metadata":{"id":"bE4ROenOrQRU"},"source":["### Clean the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dhIBqeaTrQRU","outputId":"4a8c1390-c661-4b71-e361-707744aa4cec"},"outputs":[{"ename":"ValueError","evalue":"Ensure you specified correct input image, input type, output type and/or output image path ","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)","\u001b[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\imageai\\Detection\\__init__.py\u001b[0m in \u001b[0;36mdetectCustomObjectsFromImage\u001b[1;34m(self, custom_objects, input_image, output_image_path, input_type, output_type, extract_detected_objects, minimum_percentage_probability, display_percentage_probability, display_object_name, thread_safe)\u001b[0m\n\u001b[0;32m    795\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m                         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m                         \u001b[0minput_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_image_bgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2842\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2843\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'hardhat/test'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-4-6d8480a8c66a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     detectedImage, detections = detector.detectCustomObjectsFromImage(custom_objects=peopleOnly, output_type=\"array\",\n\u001b[0;32m      7\u001b[0m                                                                       \u001b[0minput_image\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimageFile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                                                                       minimum_percentage_probability=30)\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageFile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"hardhat-clean/{0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\imageai\\Detection\\__init__.py\u001b[0m in \u001b[0;36mdetectCustomObjectsFromImage\u001b[1;34m(self, custom_objects, input_image, output_image_path, input_type, output_type, extract_detected_objects, minimum_percentage_probability, display_percentage_probability, display_object_name, thread_safe)\u001b[0m\n\u001b[0;32m    917\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m                 raise ValueError(\n\u001b[1;32m--> 919\u001b[1;33m                     \"Ensure you specified correct input image, input type, output type and/or output image path \")\n\u001b[0m\u001b[0;32m    920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: Ensure you specified correct input image, input type, output type and/or output image path "]}],"source":["hardhatImages = os.listdir(\"hardhat\")\n","peopleOnly = detector.CustomObjects(person=True)\n","\n","for i in hardhatImages:\n","    imageFile = \"hardhat/{0}\".format(i)\n","    detectedImage, detections = detector.detectCustomObjectsFromImage(custom_objects=peopleOnly, output_type=\"array\",\n","                                                                      input_image=imageFile, \n","                                                                      minimum_percentage_probability=30)\n","    if len(detections) < 0:\n","        os.remove(imageFile)"]},{"cell_type":"markdown","metadata":{"id":"h-NASLLXrQRV"},"source":["### Split the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaTPNUZdrQRW"},"outputs":[],"source":["if not os.path.exists('hardhat/train/images'):\n","    os.makedirs('hardhat/train/images')\n","if not os.path.exists('hardhat/validation/images'):\n","    os.makedirs('hardhat/validation/images')\n","\n","hardhatImages = os.listdir(\"hardhat\")\n","hardhatTrainNums = round(len(hardhatImages) * 0.90)\n","\n","for i in range(0, hardhatTrainNums):\n","    file = \"hardhat/\" + hardhatImages[i]\n","    if os.path.isfile(file):\n","        os.rename(file, \"hardhat/train/images/\" + hardhatImages[i])\n","    \n","hardhatImages = os.listdir(\"hardhat\")\n","\n","for i in hardhatImages:\n","    file = \"hardhat/\" + i\n","    if os.path.isfile(file):\n","        os.rename(file, \"hardhat/validation/images/\" + i)"]},{"cell_type":"markdown","metadata":{"id":"1SqaXI-FrQRX"},"source":["### Train the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OYL9njHorQRX","outputId":"087b3391-96cf-4de9-b2a5-3614fed4c687"},"outputs":[{"name":"stdout","output_type":"stream","text":["Generating anchor boxes for training images and annotation...\n","Average IOU for 9 anchors: 0.75\n","Anchor Boxes generated.\n","Detection configuration saved in  hardhat\\json\\detection_config.json\n","Training on: \t['person hardhat']\n","Training with Batch Size:  4\n","Number of Experiments:  200\n","Training with transfer learning from pretrained Model\n"]},{"name":"stderr","output_type":"stream","text":["E:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\keras\\callbacks\\callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n","  warnings.warn('`epsilon` argument is deprecated and '\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n","944/944 [==============================] - 856s 907ms/step - loss: 36.9858 - yolo_layer_16_loss: 7.0103 - yolo_layer_17_loss: 10.9458 - yolo_layer_18_loss: 19.0297 - val_loss: 22.8127 - val_yolo_layer_16_loss: 5.6805 - val_yolo_layer_17_loss: 6.6321 - val_yolo_layer_18_loss: 12.3109\n","WARNING:tensorflow:From E:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n","Epoch 2/200\n","944/944 [==============================] - 774s 820ms/step - loss: 20.2127 - yolo_layer_16_loss: 4.6473 - yolo_layer_17_loss: 5.6500 - yolo_layer_18_loss: 9.9154 - val_loss: 12.3263 - val_yolo_layer_16_loss: 5.5798 - val_yolo_layer_17_loss: 6.8109 - val_yolo_layer_18_loss: 11.0726\n","Epoch 3/200\n","944/944 [==============================] - 776s 822ms/step - loss: 18.3042 - yolo_layer_16_loss: 4.7082 - yolo_layer_17_loss: 4.9417 - yolo_layer_18_loss: 8.6543 - val_loss: 30.1679 - val_yolo_layer_16_loss: 3.5330 - val_yolo_layer_17_loss: 5.7483 - val_yolo_layer_18_loss: 10.3959\n","Epoch 4/200\n","944/944 [==============================] - 772s 817ms/step - loss: 15.8019 - yolo_layer_16_loss: 3.5019 - yolo_layer_17_loss: 4.2786 - yolo_layer_18_loss: 8.0214 - val_loss: 25.0318 - val_yolo_layer_16_loss: 3.3268 - val_yolo_layer_17_loss: 4.8476 - val_yolo_layer_18_loss: 8.9261\n","Epoch 5/200\n","944/944 [==============================] - 775s 821ms/step - loss: 14.2383 - yolo_layer_16_loss: 2.8789 - yolo_layer_17_loss: 3.9230 - yolo_layer_18_loss: 7.4365 - val_loss: 20.3871 - val_yolo_layer_16_loss: 2.7601 - val_yolo_layer_17_loss: 4.3188 - val_yolo_layer_18_loss: 8.2737\n","Epoch 6/200\n","944/944 [==============================] - 774s 820ms/step - loss: 13.3032 - yolo_layer_16_loss: 2.6941 - yolo_layer_17_loss: 3.6415 - yolo_layer_18_loss: 6.9677 - val_loss: 12.4483 - val_yolo_layer_16_loss: 2.4334 - val_yolo_layer_17_loss: 4.4343 - val_yolo_layer_18_loss: 7.3737\n","Epoch 7/200\n","944/944 [==============================] - 773s 819ms/step - loss: 12.7051 - yolo_layer_16_loss: 2.4235 - yolo_layer_17_loss: 3.3868 - yolo_layer_18_loss: 6.8948 - val_loss: 13.0070 - val_yolo_layer_16_loss: 2.1589 - val_yolo_layer_17_loss: 4.2864 - val_yolo_layer_18_loss: 7.7522\n","Epoch 8/200\n","944/944 [==============================] - 774s 820ms/step - loss: 12.0266 - yolo_layer_16_loss: 2.3517 - yolo_layer_17_loss: 3.1444 - yolo_layer_18_loss: 6.5304 - val_loss: 10.2641 - val_yolo_layer_16_loss: 2.4435 - val_yolo_layer_17_loss: 3.8413 - val_yolo_layer_18_loss: 7.1583\n","Epoch 9/200\n","944/944 [==============================] - 774s 819ms/step - loss: 11.5796 - yolo_layer_16_loss: 2.0791 - yolo_layer_17_loss: 3.0983 - yolo_layer_18_loss: 6.4023 - val_loss: 16.9550 - val_yolo_layer_16_loss: 1.9408 - val_yolo_layer_17_loss: 3.7394 - val_yolo_layer_18_loss: 8.5159\n","Epoch 10/200\n","944/944 [==============================] - 773s 819ms/step - loss: 11.0530 - yolo_layer_16_loss: 2.0455 - yolo_layer_17_loss: 2.9342 - yolo_layer_18_loss: 6.0733 - val_loss: 11.9410 - val_yolo_layer_16_loss: 2.4114 - val_yolo_layer_17_loss: 3.6174 - val_yolo_layer_18_loss: 7.4209\n","Epoch 11/200\n","944/944 [==============================] - 776s 822ms/step - loss: 10.6817 - yolo_layer_16_loss: 1.9981 - yolo_layer_17_loss: 2.8343 - yolo_layer_18_loss: 5.8493 - val_loss: 7.0664 - val_yolo_layer_16_loss: 1.9985 - val_yolo_layer_17_loss: 3.6278 - val_yolo_layer_18_loss: 6.6847\n","Epoch 12/200\n","944/944 [==============================] - 774s 820ms/step - loss: 10.4226 - yolo_layer_16_loss: 1.9022 - yolo_layer_17_loss: 2.7187 - yolo_layer_18_loss: 5.8017 - val_loss: 13.9414 - val_yolo_layer_16_loss: 2.1432 - val_yolo_layer_17_loss: 3.8370 - val_yolo_layer_18_loss: 6.8831\n","Epoch 13/200\n","944/944 [==============================] - 775s 821ms/step - loss: 10.0310 - yolo_layer_16_loss: 1.8245 - yolo_layer_17_loss: 2.6859 - yolo_layer_18_loss: 5.5206 - val_loss: 11.2866 - val_yolo_layer_16_loss: 1.8409 - val_yolo_layer_17_loss: 3.3783 - val_yolo_layer_18_loss: 6.5706\n","Epoch 14/200\n","944/944 [==============================] - 775s 821ms/step - loss: 9.7983 - yolo_layer_16_loss: 1.7165 - yolo_layer_17_loss: 2.5344 - yolo_layer_18_loss: 5.5474 - val_loss: 15.4132 - val_yolo_layer_16_loss: 1.7203 - val_yolo_layer_17_loss: 3.8468 - val_yolo_layer_18_loss: 6.7124\n","Epoch 15/200\n","944/944 [==============================] - 774s 820ms/step - loss: 9.6199 - yolo_layer_16_loss: 1.6960 - yolo_layer_17_loss: 2.5321 - yolo_layer_18_loss: 5.3918 - val_loss: 11.7558 - val_yolo_layer_16_loss: 1.6791 - val_yolo_layer_17_loss: 3.3249 - val_yolo_layer_18_loss: 6.7528\n","Epoch 16/200\n","944/944 [==============================] - 778s 824ms/step - loss: 9.2273 - yolo_layer_16_loss: 1.6217 - yolo_layer_17_loss: 2.3432 - yolo_layer_18_loss: 5.2624 - val_loss: 17.8903 - val_yolo_layer_16_loss: 1.8734 - val_yolo_layer_17_loss: 3.7065 - val_yolo_layer_18_loss: 6.7896\n","Epoch 17/200\n","944/944 [==============================] - 778s 825ms/step - loss: 9.0276 - yolo_layer_16_loss: 1.5986 - yolo_layer_17_loss: 2.3144 - yolo_layer_18_loss: 5.1147 - val_loss: 8.6253 - val_yolo_layer_16_loss: 1.6680 - val_yolo_layer_17_loss: 3.7442 - val_yolo_layer_18_loss: 5.6655\n","Epoch 18/200\n","944/944 [==============================] - 780s 827ms/step - loss: 8.8141 - yolo_layer_16_loss: 1.5611 - yolo_layer_17_loss: 2.3312 - yolo_layer_18_loss: 4.9219 - val_loss: 6.8751 - val_yolo_layer_16_loss: 1.4509 - val_yolo_layer_17_loss: 3.2254 - val_yolo_layer_18_loss: 6.5645\n","Epoch 19/200\n","944/944 [==============================] - 779s 825ms/step - loss: 8.6509 - yolo_layer_16_loss: 1.5625 - yolo_layer_17_loss: 2.2129 - yolo_layer_18_loss: 4.8754 - val_loss: 4.2779 - val_yolo_layer_16_loss: 1.4135 - val_yolo_layer_17_loss: 3.0607 - val_yolo_layer_18_loss: 6.1202\n","Epoch 20/200\n","944/944 [==============================] - 812s 860ms/step - loss: 8.4625 - yolo_layer_16_loss: 1.4308 - yolo_layer_17_loss: 2.1983 - yolo_layer_18_loss: 4.8334 - val_loss: 19.4190 - val_yolo_layer_16_loss: 1.4224 - val_yolo_layer_17_loss: 3.5843 - val_yolo_layer_18_loss: 7.1598\n","Epoch 21/200\n","944/944 [==============================] - 824s 872ms/step - loss: 8.3525 - yolo_layer_16_loss: 1.4480 - yolo_layer_17_loss: 2.2054 - yolo_layer_18_loss: 4.6992 - val_loss: 14.1312 - val_yolo_layer_16_loss: 1.6272 - val_yolo_layer_17_loss: 2.7905 - val_yolo_layer_18_loss: 5.9421\n","Epoch 22/200\n","682/944 [====================>.........] - ETA: 3:37 - loss: 8.1493 - yolo_layer_16_loss: 1.3431 - yolo_layer_17_loss: 2.0674 - yolo_layer_18_loss: 4.7388"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-21-cdca61b8cf02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                        train_from_pretrained_model=\"yolo.h5\")\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\imageai\\Detection\\Custom\\__init__.py\u001b[0m in \u001b[0;36mtrainModel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m             \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m         )\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from imageai.Detection.Custom import DetectionModelTrainer\n","\n","trainer = DetectionModelTrainer()\n","trainer.setModelTypeAsYOLOv3()\n","trainer.setDataDirectory(data_directory=\"hardhat\")\n","\n","trainer.setTrainConfig(object_names_array=[\"person hardhat\"], batch_size=4, num_experiments=200, \n","                       train_from_pretrained_model=\"yolo.h5\")\n","\n","trainer.trainModel()"]},{"cell_type":"markdown","metadata":{"id":"-8Pb6fTUrQRY"},"source":["### Evaluate the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rva1lIjirQRY","outputId":"72629ab7-98ed-49e1-8f8b-a7ae408da2a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting Model evaluation....\n","Model File:  hardhat\\models\\detection_model-ex-005--loss-0014.238.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","person hardhat: 0.7165\n","mAP: 0.7165\n","===============================\n","Starting Model evaluation....\n","Model File:  hardhat\\models\\detection_model-ex-010--loss-0011.053.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","person hardhat: 0.7865\n","mAP: 0.7865\n","===============================\n","Starting Model evaluation....\n","Model File:  hardhat\\models\\detection_model-ex-015--loss-0009.620.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","person hardhat: 0.8355\n","mAP: 0.8355\n","===============================\n","Starting Model evaluation....\n","Model File:  hardhat\\models\\detection_model-ex-020--loss-0008.462.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","person hardhat: 0.8446\n","mAP: 0.8446\n","===============================\n","---------------------------------------------------------\n","Iteration 05: 0.7164811838244572 Iteration 10: 0.786450228152799 Iteration 15: 0.8354553845774733 Iteration 20: 0.8446486610895216\n","---------------------------------------------------------\n"]}],"source":["model05 = trainer.evaluateModel(model_path=\"hardhat\\models\\detection_model-ex-005--loss-0014.238.h5\", \n","                      json_path=\"hardhat\\json\\detection_config.json\", iou_threshold=0.5, \n","                      object_threshold=0.3, nms_threshold=0.5)\n","model10 = trainer.evaluateModel(model_path=\"hardhat\\models\\detection_model-ex-010--loss-0011.053.h5\", \n","                      json_path=\"hardhat\\json\\detection_config.json\", iou_threshold=0.5, \n","                      object_threshold=0.3, nms_threshold=0.5)\n","model15 = trainer.evaluateModel(model_path=\"hardhat\\models\\detection_model-ex-015--loss-0009.620.h5\", \n","                      json_path=\"hardhat\\json\\detection_config.json\", iou_threshold=0.5, \n","                      object_threshold=0.3, nms_threshold=0.5)\n","model20 = trainer.evaluateModel(model_path=\"hardhat\\models\\detection_model-ex-020--loss-0008.462.h5\", \n","                      json_path=\"hardhat\\json\\detection_config.json\", iou_threshold=0.5, \n","                      object_threshold=0.3, nms_threshold=0.5)\n","\n","print('---------------------------------------------------------')\n","print('Iteration 05:', model05[0]['average_precision']['person hardhat'],\n","     'Iteration 10:', model10[0]['average_precision']['person hardhat'],\n","     'Iteration 15:', model15[0]['average_precision']['person hardhat'],\n","     'Iteration 20:', model20[0]['average_precision']['person hardhat'])\n","print('---------------------------------------------------------')"]},{"cell_type":"markdown","metadata":{"id":"4NdAXKbUrQRa"},"source":["### Random Hard Hat Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DacjAEl-rQRb","outputId":"a443b9f0-ae7d-4db4-9ed9-35ee1dd442bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["person hardhat  :  48.9349365234375  :  [198, 16, 253, 127]\n","--------------------------------\n","person hardhat  :  92.02308058738708  :  [84, 71, 127, 114]\n","--------------------------------\n"]}],"source":["from imageai.Detection.Custom import CustomObjectDetection\n","\n","detector = CustomObjectDetection()\n","detector.setModelTypeAsYOLOv3()\n","detector.setModelPath(\"hardhat\\models\\detection_model-ex-020--loss-0008.462.h5\")\n","detector.setJsonPath(\"hardhat\\json\\detection_config.json\")\n","detector.loadModel()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_dfDKl57rQRc","outputId":"334a4e25-b189-4a61-deac-3f007f59e065"},"outputs":[{"name":"stdout","output_type":"stream","text":["person hardhat  :  81.50655627250671  :  [137, 74, 194, 119]\n","--------------------------------\n","person hardhat  :  64.44770097732544  :  [290, 89, 328, 123]\n","--------------------------------\n","person hardhat  :  70.66482901573181  :  [252, 90, 290, 130]\n","--------------------------------\n","person hardhat  :  54.37401533126831  :  [358, 93, 385, 131]\n","--------------------------------\n","person hardhat  :  59.80772376060486  :  [125, 100, 145, 136]\n","--------------------------------\n","person hardhat  :  45.671346783638  :  [222, 101, 249, 130]\n","--------------------------------\n","person hardhat  :  77.1479070186615  :  [314, 99, 361, 142]\n","--------------------------------\n"]}],"source":["import random\n","\n","testImages = os.listdir(\"hardhat/validation/images\")\n","randomFile = testImages[random.randint(0, len(testImages) - 1)]\n","\n","detectedImage, detections = detector.detectObjectsFromImage(output_type=\"array\", \n","                                                            input_image=\"hardhat/validation/images/{0}\".format(randomFile), \n","                                                            minimum_percentage_probability=30)\n","showImage(detectedImage)\n","\n","for eachObject in detections:\n","    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n","    print(\"--------------------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQTOdkEtrQRd"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"Hard-Hat-Detector.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}